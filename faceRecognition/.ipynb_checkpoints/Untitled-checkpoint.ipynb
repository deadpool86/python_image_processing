{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_color_one(name):\n",
    "#     color = [(ord(c.lower())-97)*8 for c in name[:3]]\n",
    "    color = []\n",
    "    for c in name[:3]:\n",
    "        val = ord(c.lower())\n",
    "        val = (val - 97) * 8\n",
    "        color.append(val)\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_color_two(name):\n",
    "    color = [(ord(c.lower())-97)*8 for c in name[:3]]\n",
    "#     color = []\n",
    "#     for c in name[:3]:\n",
    "#         val = ord(c.lower())\n",
    "#         val = (val - 97) * 8\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"kry_baby\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 136, 192]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_color_one(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 136, 192]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_color_two(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8b2ab3991dae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "int(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f9f08aac9536>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'a'"
     ]
    }
   ],
   "source": [
    "int(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26 * 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading known faces...\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print('Loading known faces...')\n",
    "known_faces = []\n",
    "known_names = []\n",
    "\n",
    "KNOWN_FACES_DIR = 'known_faces'\n",
    "for name in os.listdir(KNOWN_FACES_DIR): #loads the dir in the known_faces_folder\n",
    "#     print(name)\n",
    "    \n",
    "    for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n",
    "#         print(filename)\n",
    "        image = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}/{name}/{filename}')\n",
    "    \n",
    "#       learn how to recognize a face\n",
    "        encoding = face_recognition.face_encodings(image)\n",
    "        if len(encoding) == 0:\n",
    "            continue\n",
    "            \n",
    "        known_faces.append(encoding[0])\n",
    "        known_names.append(name)\n",
    "print(len(known_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-45d94c67e925>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arvind', 'Kashish']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arvind\n",
      "Kashish\n"
     ]
    }
   ],
   "source": [
    "for name in known_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(known_faces[0][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = known_faces[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "KNOWN_FACES_DIR = 'known_faces'\n",
    "UNKNOWN_FACES_DIR = 'unknown_faces'\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = 'hog'  \n",
    "\n",
    "for name in os.listdir(KNOWN_FACES_DIR): #loads the dir in the known_faces_folder\n",
    "#     print(name)\n",
    "    \n",
    "    for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n",
    "#         print(filename)\n",
    "        image = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}/{name}/{filename}')\n",
    "    \n",
    "#       learn how to recognize a face\n",
    "        encoding = face_recognition.face_encodings(image)\n",
    "        if len(encoding) == 0:\n",
    "            continue\n",
    "            \n",
    "        known_faces.append(encoding[0])\n",
    "        known_names.append(name)\n",
    "print(len(known_faces))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#unknown faces has some image \n",
    "UNKNOWN_FACES_DIR = 'unknown_faces_test'\n",
    "\n",
    "# take each image in unknown_faces\n",
    "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
    "    \n",
    "    if filename == '.ipynb_checkpoints/':\n",
    "        continue\n",
    "    # print the name of the file\n",
    "    print(f'Filename {filename}', end='')\n",
    "    \n",
    "    #load image file and store in image\n",
    "    image = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}/{filename}', mode=\"RGB\")\n",
    "    \n",
    "    #get all the faces in the image\n",
    "    locations = face_recognition.face_locations(image)\n",
    "    \n",
    "    #know how to recognize the image based on locations\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "    \n",
    "    #convert color channel from bgr2rgb\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    #print the number of faces found \n",
    "    print(f', found {len(encodings)} face(s)')\n",
    "    \n",
    "    if(len(encodings) == 0):\n",
    "        continue\n",
    "    \n",
    "    names_in_the_image = []\n",
    "    #make pair of the face_location with corresponding encoding\n",
    "    for (top, right, bottom, left), face_encoding in zip(locations, encodings):\n",
    "        \n",
    "        ## compare the cur_face encoding and check if it matches to a known face\n",
    "        matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "        \n",
    "        ######### initialize the name to None #########\n",
    "        name = None\n",
    "        \n",
    "        ########## find the best match index using the encondings ##########\n",
    "        face_distances  = face_recognition.face_distance(known_faces, face_encoding)\n",
    "        \n",
    "        ######## find the index of the minimum face distance \n",
    "        ####### as this is the best match\n",
    "        best_match_index = np.argmin(face_distances) # returns index of min Value\n",
    "        \n",
    "        ######### check if there is a match,  get the name at best match index\n",
    "        if matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "        \n",
    "        if name:\n",
    "            names_in_the_image.append(name)\n",
    "            \n",
    "        ####### show a rectangle on the face\n",
    "        top_left = (left, top)\n",
    "        bottom_right = (right, bottom)\n",
    "        \n",
    "        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 5)\n",
    "        \n",
    "        ###### show the name of the person below the rectangle\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        cv2.putText(image, name, (left + 10, bottom + 15), font, 0.5, (200, 200, 200), 10)\n",
    "        \n",
    "        \n",
    "    ######### get the name from the names_in_the_image and push the image to that folder ########\n",
    "    for name in names_in_the_image:\n",
    "        \n",
    "        ########## get folder by name #######\n",
    "#         path = os.path.join(KNOWN_FACES_DIR, name)\n",
    "        \n",
    "#         ###### write the image in this path ###########\n",
    "#         cv2.imwrite(f'{KNOWN_FACES_DIR}/{name}/{filename}', image)\n",
    "        print(f'{name} ')\n",
    "    print(\"\\n\")\n",
    "        \n",
    "#         shutil.copy(image, path)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'known_faces\\\\Kashish'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(KNOWN_FACES_DIR, name)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Projects_and_Works\\\\computerVision_ImageProcessing\\\\faceRecognition'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Projects_and_Works\\\\computerVision_ImageProcessing\\\\faceRecognition\\\\Kashish'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_FACES_DIR = 'known_faces_test'\n",
    "UNKNOWN_FACES_DIR = 'unknown_faces_test'\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = 'hog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading known faces...\n",
      "1.jpeg\n",
      "kashish_face_3.jpeg\n",
      " we found total 2 faces\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading known faces...')\n",
    "known_faces = []\n",
    "known_names = []\n",
    "\n",
    "#get all the folders in cwd\n",
    "for name in os.listdir(KNOWN_FACES_DIR):\n",
    "    \n",
    "    #for each file in the folder\n",
    "    for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n",
    "        print(filename)\n",
    "        \n",
    "        if os.path.isdir(filename):\n",
    "            continue\n",
    "        \n",
    "        #load the image to face_recognition api\n",
    "        image = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}/{name}/{filename}')\n",
    "        \n",
    "        #learn how to recognize the given above image\n",
    "        encoding = face_recognition.face_encodings(image, model=MODEL)\n",
    "        \n",
    "        #check if we found a face\n",
    "        if len(encoding) == 0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #push the encoded face in the known_face\n",
    "        known_faces.append(encoding[0])\n",
    "        \n",
    "        #push the name of the person in known_names\n",
    "        known_names.append(name)\n",
    "\n",
    "\n",
    "print(f' we found total {len(known_faces)} faces\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unknown faces...\n"
     ]
    }
   ],
   "source": [
    "print('Processing unknown faces...')\n",
    " \n",
    "#unknown faces has some image \n",
    "# UNKNOWN_FACES_DIR = 'unknown_faces_test'\n",
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "######## define a function that can take in an image and draw a rectangle and write name of the person\n",
    "############### detect_faces_in_unknown_image(image, locations, encodings, names_in_th\n",
    "def detect_faces_in_unknown_image(image, locations, encodings, names_in_the_image = []):\n",
    "    global known_faces, TOLERANCE\n",
    "    \n",
    "    image_copy = image.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "     # image = detectFacesInUnknownImages(image, locations, encodings) \n",
    "    for (top, right, bottom, left), face_encoding in zip(locations, encodings):\n",
    "        \n",
    "        ## compare the cur_face encoding and check if it matches to a known face\n",
    "        matches = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        \n",
    "        ######### initialize the name to None #########\n",
    "        name = None\n",
    "        \n",
    "        ########## find the best match index using the encondings ##########\n",
    "        face_distances  = face_recognition.face_distance(known_faces, face_encoding)\n",
    "        \n",
    "        ######## find the index of the minimum face distance \n",
    "        ####### as this is the best match\n",
    "        best_match_index = np.argmin(face_distances) # returns index of min Value\n",
    "        \n",
    "        ######### check if there is a match,  get the name at best match index\n",
    "        if matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "        \n",
    "        if name:\n",
    "            names_in_the_image.append(name)\n",
    "            \n",
    "        ####### show a rectangle on the face\n",
    "        top_left = (left, top)\n",
    "        bottom_right = (right, bottom)\n",
    "        \n",
    "        cv2.rectangle(image_copy, top_left, bottom_right, (0, 255, 0), 5)\n",
    "        \n",
    "        ###### show the name of the person below the rectangle\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        cv2.putText(image_copy, name, (left + 10, bottom + 15), font, 0.5, (200, 200, 200), 10)\n",
    "        \n",
    "        return image_copy, names_in_the_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename 13.jpg, found 1 face(s)\n",
      "\n",
      "\n",
      "Filename 14.jpg, found 1 face(s)\n",
      "\n",
      "\n",
      "Filename 15.jpg, found 0 face(s)\n",
      "Filename 16.jpg, found 3 face(s)\n",
      "Kashish \n",
      "Arvind \n",
      "Kashish \n",
      "\n",
      "\n",
      "Filename 18.jpg, found 0 face(s)\n",
      "Filename 19.jpg, found 0 face(s)\n",
      "Filename 20.jpg, found 0 face(s)\n",
      "Filename 21.jpg, found 2 face(s)\n",
      "Kashish \n",
      "Arvind \n",
      "\n",
      "\n",
      "Filename 23.jpg"
     ]
    }
   ],
   "source": [
    "#unknown faces has some image \n",
    "UNKNOWN_FACES_DIR = 'unknown_faces_test'\n",
    "\n",
    "# take each image in unknown_faces\n",
    "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
    "    \n",
    "    if filename == '.ipynb_checkpoints/':\n",
    "        continue\n",
    "    # print the name of the file\n",
    "    print(f'Filename {filename}', end='')\n",
    "    \n",
    "    #load image file and store in image\n",
    "    image = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}/{filename}', mode=\"RGB\")\n",
    "    \n",
    "    #get all the faces in the image\n",
    "    locations = face_recognition.face_locations(image)\n",
    "    \n",
    "    #know how to recognize the image based on locations\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "    \n",
    "    #convert color channel from bgr2rgb\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    #print the number of faces found \n",
    "    print(f', found {len(encodings)} face(s)')\n",
    "    \n",
    "    if(len(encodings) == 0):\n",
    "        continue\n",
    "    \n",
    "    names_in_the_image = []\n",
    "    #make pair of the face_location with corresponding encoding\n",
    "    for (top, right, bottom, left), face_encoding in zip(locations, encodings):\n",
    "        \n",
    "        ## compare the cur_face encoding and check if it matches to a known face\n",
    "        matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "        \n",
    "        ######### initialize the name to None #########\n",
    "        name = None\n",
    "        \n",
    "        ########## find the best match index using the encondings ##########\n",
    "        face_distances  = face_recognition.face_distance(known_faces, face_encoding)\n",
    "        \n",
    "        ######## find the index of the minimum face distance \n",
    "        ####### as this is the best match\n",
    "        best_match_index = np.argmin(face_distances) # returns index of min Value\n",
    "        \n",
    "        ######### check if there is a match,  get the name at best match index\n",
    "        if matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "        \n",
    "        if name:\n",
    "            names_in_the_image.append(name)\n",
    "            \n",
    "        ####### show a rectangle on the face\n",
    "        top_left = (left, top)\n",
    "        bottom_right = (right, bottom)\n",
    "        \n",
    "        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 5)\n",
    "        \n",
    "        ###### show the name of the person below the rectangle\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        cv2.putText(image, name, (left + 10, bottom + 15), font, 0.5, (200, 200, 200), 10)\n",
    "        \n",
    "        \n",
    "    ######### get the name from the names_in_the_image and push the image to that folder ########\n",
    "    for name in names_in_the_image:\n",
    "        \n",
    "        ########## get folder by name #######\n",
    "#         path = os.path.join(KNOWN_FACES_DIR, name)\n",
    "        \n",
    "#         ###### write the image in this path ###########\n",
    "#         cv2.imwrite(f'{KNOWN_FACES_DIR}/{name}/{filename}', image)\n",
    "        print(f'{name} ')\n",
    "    print(\"\\n\")\n",
    "        \n",
    "#         shutil.copy(image, path)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
